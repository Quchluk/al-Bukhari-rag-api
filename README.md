# ğŸ“– Ask al-Bukhari â€” RAG Question Answering App

This is a simple Retrieval-Augmented Generation (RAG) web app built with [Streamlit](https://streamlit.io/) and [LangChain](https://www.langchain.com/), using a FAISS vector index and the free `deepseek-chat-v3-0324` model via [OpenRouter](https://openrouter.ai/).

---

## ğŸ§  Features

- Semantic question answering over a curated hadith corpus (Al-Bukhari)
- FAISS-based vector retrieval
- OpenAI embeddings (locally stored, no runtime cost)
- DeepSeek LLM via OpenRouter (completely free)
- Streamlit-based interface

---

ğŸŒ Try it Live

The app is fully deployed and freely accessible at:

ğŸ”— https://al-bukhari-rag.onrender.com

---

## ğŸ’» Local Setup

### Prerequisites

- Python 3.9+
- `pip`

### Installation

```bash
git clone https://github.com/yourusername/al-bukhari-rag.git
cd al-bukhari-rag
pip install -r requirements.txt

Configure your environment

Create a .env file and add your API keys:

OPENAI_API_KEY=your_openai_key
OPENROUTER_API_KEY=your_openrouter_key

Run the app

streamlit run app.py

Then open http://localhost:8501 in your browser.

â¸»

ğŸ“‚ Project Structure

.
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ faiss_index/         # FAISS index with OpenAI embeddings
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env.example         # Environment variable template
â”œâ”€â”€ render.yaml          # Render deployment config
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


â¸»

ğŸ›¡ï¸ Privacy & Cost Notes
	â€¢	FAISS index is loaded locally. No OpenAI requests are made during query time.
	â€¢	DeepSeek is called via OpenRouter and is entirely free at the time of writing.
	â€¢	You only need OPENAI_API_KEY for loading the index, not for runtime inference.

â¸»

ğŸ“¬ License

MIT â€” Free to use and modify.

---
